{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6159270-7138-4192-9d84-225125bb3941",
   "metadata": {},
   "source": [
    "# Fenotipagem de tomateiro resistente à requeima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb80969a-b54e-4389-af2b-872f0da7ea14",
   "metadata": {},
   "source": [
    "## Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6aac25-689f-4d24-b357-3f25c70a2010",
   "metadata": {},
   "source": [
    "A fenotipagem é o processo de avaliação de características mensuráveis, como peso, formato dos frutos e estruturas vegetais. O uso de imagens capturadas em diferentes regiões do espectro eletromagnético permite estimar medidas essenciais, como altura, largura e número de folhas, para monitorar o crescimento vegetativo.\n",
    "\n",
    "A requeima, ou *mela*, é uma doença causada pelo oomiceto *Phytophthora infestans*, que afeta culturas de tomate. Embora possa causar a perda total da cultura, existem cultivares resistentes à doença. Experimentos com diferentes variedades podem avaliar a severidade da requeima em diversas cultivares, utilizando imagens de drone.\n",
    "\n",
    "De acordo com o Código Internacional de Nomenclatura de Plantas Cultivadas (**ICNCP**), uma cultivar é definida como um \"*conjunto de plantas selecionado por atributos específicos ou combinação de atributos*\". Dada a variedade de cultivares disponíveis, um experimento foi conduzido com o uso de imagens de drone, que foram processadas e analisadas com ferramentas de *machine learning* para economizar tempo e recursos.\n",
    "\n",
    "Uma câmera multiespectral **MicaSense**, equipada com cinco bandas espectrais (RGB, infravermelho próximo (NIR) e Red Edge), foi utilizada para capturar as imagens. Os índices de vegetação, calculados a partir dessas bandas espectrais, foram processados e resultaram no *dataset* utilizado para prever a severidade da requeima.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619887d0-cf79-4919-b201-c7082393373d",
   "metadata": {},
   "source": [
    "## Análise preditiva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a78b9b-4b69-4944-b100-e5f1bd8401bc",
   "metadata": {},
   "source": [
    "### Importamos as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84493c54-2d74-4c97-8e56-131220b09e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor \n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.svm import SVR \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score \n",
    "from sklearn.feature_selection import RFE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481c7009-2cbb-401a-aef0-2e0f8e5c2f14",
   "metadata": {},
   "source": [
    "### Carregamos o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b572afef-bcbd-4df6-9b98-509061642a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_sintetico.csv')\n",
    "\n",
    "X = df.drop(['id', 'Severidade'], axis = 1)\n",
    "Y = df['Severidade']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa455e88-3409-45db-9d52-b070f0a02319",
   "metadata": {},
   "source": [
    "### Extraímos uma amostra dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53105cc1-b171-42a6-8598-a63bf4d908b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadfd512-5e18-415a-8d56-33137cd7803a",
   "metadata": {},
   "source": [
    "### Funções para ajuste dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839c7e36-8f65-4002-a10f-8555762031e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_regressor():\n",
    "    neigh_score = []\n",
    "    for i in range(1, 30):\n",
    "        knn = KNeighborsRegressor(n_neighbors=i)\n",
    "        knn.fit(X_train, Y_train)\n",
    "        pred = knn.predict(X_test)\n",
    "        score = (mean_squared_error(Y_test, pred)**0.5)\n",
    "        neigh_score.append((i, score))\n",
    "    \n",
    "    # Seleciona o k com o menor erro\n",
    "    k = min(neigh_score, key=lambda x: x[1])[0]\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc67d650-e4de-4c9f-8a26-366150be69c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svr_regressor():\n",
    "    svr_scores = []\n",
    "    for c in [0.01, 0.1, 1, 10, 100]:\n",
    "        svr = SVR(C=c)\n",
    "        svr.fit(X_train, Y_train)\n",
    "        pred = svr.predict(X_test)\n",
    "        score = mean_squared_error(Y_test, pred)\n",
    "        svr_scores.append((c, score))\n",
    "    \n",
    "    # Seleciona o C com o menor erro\n",
    "    best_c = min(svr_scores, key=lambda x: x[1])[0]\n",
    "    svr = SVR(C=best_c)\n",
    "    return svr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140b8a07-8b93-415f-b6b1-fd6743776bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_regressor():\n",
    "    tree_scores = []\n",
    "    for depth in range(1, 30):\n",
    "        tree = DecisionTreeRegressor(max_depth=depth)\n",
    "        tree.fit(X_train, Y_train)\n",
    "        pred = tree.predict(X_test)\n",
    "        score = mean_squared_error(Y_test, pred)\n",
    "        tree_scores.append((depth, score))\n",
    "    \n",
    "    # Seleciona a profundidade com o menor erro\n",
    "    best_depth = min(tree_scores, key=lambda x: x[1])[0]\n",
    "    tree = DecisionTreeRegressor(max_depth=best_depth)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc5d0b0-e5d0-4eaa-ab59-86baad4c3294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_regressor():\n",
    "    forest_scores = []\n",
    "    for n in range(10, 200, 10):\n",
    "        forest = RandomForestRegressor(n_estimators=n)\n",
    "        forest.fit(X_train, Y_train)\n",
    "        pred = forest.predict(X_test)\n",
    "        score = mean_squared_error(Y_test, pred)\n",
    "        forest_scores.append((n, score))\n",
    "    \n",
    "    # Seleciona o número de árvores com o menor erro\n",
    "    best_n = min(forest_scores, key=lambda x: x[1])[0]\n",
    "    forest = RandomForestRegressor(n_estimators=best_n)\n",
    "    return forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bff90a1-7b95-4f84-9e4d-d80cd500e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_gradient_boosting_regressor():\n",
    "    hgb_scores = []\n",
    "    for l_rate in [0.01, 0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "        hgb = HistGradientBoostingRegressor(learning_rate=l_rate)\n",
    "        hgb.fit(X_train, Y_train)\n",
    "        pred = hgb.predict(X_test)\n",
    "        score = mean_squared_error(Y_test, pred)\n",
    "        hgb_scores.append((l_rate, score))\n",
    "    \n",
    "    # Seleciona a taxa de aprendizado com o menor erro\n",
    "    best_rate = min(hgb_scores, key=lambda x: x[1])[0]\n",
    "    hgb = HistGradientBoostingRegressor(learning_rate=best_rate)\n",
    "    return hgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ba3a4e-46f1-429a-a577-68ecfce3928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelos = {\"Regressão Linear\": LinearRegression, \"KNN\": KNeighborsRegressor, \"SVR\": svr_regressor, \"Decision Tree\": DecisionTreeRegressor, \"Random Forest\": RandomForestRegressor, \"HGB\": HistGradientBoostingRegressor }\n",
    "tunning = {\"Regressão Linear\": LinearRegression, \"KNN\": knn_regressor, \"SVR\": svr_regressor, \"Decision Tree\": decision_tree_regressor, \"Random Forest\": random_forest_regressor, \"HGB\": hist_gradient_boosting_regressor }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58be991-eb9e-43e6-80b4-737a1ad2b86c",
   "metadata": {},
   "source": [
    "### Separamos os dados de treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e870cc1-40b6-4f31-b32f-80105e223cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4039a6a2-c2d4-40ce-b31f-602579fdbdfb",
   "metadata": {},
   "source": [
    "### Ajuste dos modelos sem pre-processamento ou seleção de \"features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6c1054-1280-4129-a5ab-9426c9a80071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo = LinearRegression()\n",
    "for name in tunning:\n",
    "    model = tunning[name]()\n",
    "    model.fit(X_train, Y_train).predict(X_train)\n",
    "    \n",
    "    print(name)\n",
    "    score = cross_val_score(model, X_train, Y_train, cv = 10, scoring='r2')\n",
    "    print(np.mean(score))\n",
    "    print(\"=======================================\")\n",
    "    \n",
    "    # plt.plot(fpr, tpr, label='%s (area = %0.2f)' % (name, roc_auc))\n",
    "    # print(X.shape)()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d531db-9158-47a8-b94b-01b1ba0aeb8f",
   "metadata": {},
   "source": [
    "### Função para seleção de \"features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f47847-f2e7-4bea-b27f-9a22ba18d8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def best_k(X, Y):\n",
    "    err = float('inf')\n",
    "    best_val = 0\n",
    "    \n",
    "    for i in range(1, X.shape[1] + 1):\n",
    "        model = LinearRegression()\n",
    "        selector = RFE(model, n_features_to_select=i)\n",
    "        X_new = selector.fit_transform(X, Y)\n",
    "        \n",
    "        scores = cross_val_score(model, X_new, Y, cv=10, scoring='neg_mean_squared_error')\n",
    "        mse = -scores.mean()\n",
    "        \n",
    "        if mse < err:\n",
    "            err = mse\n",
    "            best_val = i\n",
    "          \n",
    "    return best_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0d822d-788f-43ee-bbeb-2aa81d681445",
   "metadata": {},
   "source": [
    "### Ajustes dos modelos com pré-processamento e seleção de \"features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c079ae3-6cb4-4bf2-a1da-c56911160fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padronizando os dados\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Seleção de features usando a função best_k\n",
    "K = best_k(X, Y)\n",
    "selector = RFE(LinearRegression(), n_features_to_select=K)\n",
    "X_new = selector.fit_transform(X, Y)\n",
    "\n",
    "# Divisão os dados em treino e teste\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_new, Y, train_size=0.7)\n",
    "\n",
    "# Treinamento e validação cruzada para seleção do melhor modelo\n",
    "best_score = -float('inf')\n",
    "best_model_name = None\n",
    "best_model = None\n",
    "\n",
    "for name in tunning:\n",
    "    model = tunning[name]()\n",
    "    scores = cross_val_score(model, X_train, Y_train, cv=10, scoring='r2')\n",
    "    mean_score = scores.mean()\n",
    "    \n",
    "    print(f'Modelo: {name}, Média R2: {mean_score}')\n",
    "    \n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_model_name = name\n",
    "        best_model = model\n",
    "\n",
    "print(\"=======================================\")\n",
    "print(f\"Melhor modelo: {best_model_name} apresentou R2: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b6c940-4ea8-4222-92da-a87acde2de94",
   "metadata": {},
   "source": [
    "# Avaliação do melhor modelo no conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f04f8d-d07a-485e-b3fc-a878cafa37b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X_train, Y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(Y_test, y_pred)\n",
    "mse = (mean_squared_error(Y_test, y_pred))**0.5\n",
    "mae = mean_absolute_error(Y_test, y_pred)\n",
    "\n",
    "print(\"Avaliação do modelo final com os dados de teste\")\n",
    "print('r2:', r2)\n",
    "print('mse:', mse)\n",
    "print('mae:', mae)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
